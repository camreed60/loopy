{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Loopy_sim import LoopySim\n",
    "from Lunacy_class import LunacyMultiTool, LunacyMulticlassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set number of lobes for Loopy's morphology, and then create the Loopy simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lobes = 4\n",
    "\n",
    "sim = LoopySim(lobes=num_lobes)\n",
    "datafile = f'data/loopy_{num_lobes}L_dataset.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate the loopy dataset for the given morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.loopy_dataset_generator(dx=5, dy=5, dtheta=10, filename=datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize the generated dataset of the given morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('noise')\n",
    "sim.visualize_label_from_csv(datafile, 'noise', num_samples=1500, plot_height=100, save_image=False)\n",
    "print('predator')\n",
    "sim.visualize_label_from_csv(datafile, 'predator', num_samples=1500, plot_height=100, save_image=False)\n",
    "print('prey')\n",
    "sim.visualize_label_from_csv(datafile, 'prey', num_samples=1500, plot_height=100, save_image=False)\n",
    "\n",
    "background_image = sim.predator_image_creator()\n",
    "x_coords, y_coords = sim.generate_loopy_coords()\n",
    "sim.overlay_loopy_on_image(background_image, x_coords, y_coords, x_pos=50, y_pos=50, rotation=0, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the network architecture and load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 36  \n",
    "single_layers = 17\n",
    "num_multi_layers = 18-single_layers  \n",
    "num_classes = 3\n",
    "\n",
    "model = LunacyMulticlassifier(input_size, num_classes, single_layers, num_multi_layers)\n",
    "lunacy = LunacyMultiTool(datafile, model, sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunacy.train_model(num_epochs=10000, lr=0.01, directory=\"multi_weights\", class_labels=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the best weights, that I have trained and visualize a validation data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunacy.load_weights(f'best_weights\\lunacy_multi_single_4L_80_83_86.pth')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "lunacy.visualize_with_loopy(150, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform the cellular level microscopic validations for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = lunacy.micro_validate_model()\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", results[\"confusion_matrix\"])\n",
    "print(\"Accuracy:\", results[\"accuracy\"])\n",
    "print(\"Precision:\", results[\"precision\"])\n",
    "print(\"Recall:\", results[\"recall\"])\n",
    "print(\"F1 Score:\", results[\"f1_score\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform the loopy level macroscopic validations for the model with a given threshold for minimum concensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = lunacy.macro_validate_model(threshold=50, plot=True)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", results[\"confusion_matrix\"])\n",
    "print(\"Accuracy:\", results[\"accuracy\"])\n",
    "print(\"Precision:\", results[\"precision\"])\n",
    "print(\"Recall:\", results[\"recall\"])\n",
    "print(\"F1 Score:\", results[\"f1_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the validation metrics over the minimum consensus threshold for the given loopy morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0, 101, 10)\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    results = lunacy.macro_validate_model(threshold=threshold, plot=False)\n",
    "    accuracies.append(results['accuracy'])\n",
    "    precisions.append(results['precision'])\n",
    "    recalls.append(results['recall'])\n",
    "    f1_scores.append(results['f1_score'])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, accuracies, label='Accuracy', marker='o')\n",
    "plt.plot(thresholds, precisions, label='Precision', marker='s')\n",
    "plt.plot(thresholds, recalls, label='Recall', marker='^')\n",
    "plt.plot(thresholds, f1_scores, label='F1 Score', marker='d')\n",
    "\n",
    "plt.xlabel('Threshold (%)')\n",
    "plt.ylabel('Performance Metric Value')\n",
    "plt.title('Macro Metrics vs. Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(thresholds)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in all the best weights across all three morphologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 36  \n",
    "single_layers = 17\n",
    "num_multi_layers = 18-single_layers  \n",
    "num_classes = 3\n",
    "\n",
    "num_lobes = 5\n",
    "datafile = f'data/loopy_{num_lobes}L_dataset.csv'\n",
    "sim = LoopySim(lobes=num_lobes)\n",
    "model = LunacyMulticlassifier(input_size, num_classes, single_layers, num_multi_layers)\n",
    "lunacy5 = LunacyMultiTool(datafile, model, sim)\n",
    "lunacy5.load_weights(f'best_weights\\lunacy_multi_single_5L_83_85_83_80.pth')\n",
    "\n",
    "num_lobes = 4\n",
    "datafile = f'data/loopy_{num_lobes}L_dataset.csv'\n",
    "sim = LoopySim(lobes=num_lobes)\n",
    "model = LunacyMulticlassifier(input_size, num_classes, single_layers, num_multi_layers)\n",
    "lunacy4 = LunacyMultiTool(datafile, model, sim)\n",
    "lunacy4.load_weights(f'best_weights\\lunacy_multi_single_4L_80_83_86.pth')\n",
    "\n",
    "num_lobes = 3\n",
    "datafile = f'data/loopy_{num_lobes}L_dataset.csv'\n",
    "sim = LoopySim(lobes=num_lobes)\n",
    "model = LunacyMulticlassifier(input_size, num_classes, single_layers, num_multi_layers)\n",
    "lunacy3 = LunacyMultiTool(datafile, model, sim)\n",
    "lunacy3.load_weights(f'best_weights\\lunacy_multi_single_3L_81_74_83_87.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform all validations across all morphologies with all the best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform micro validation for each morphology\n",
    "micro_metrics_5 = lunacy5.micro_validate_model(plot=False)\n",
    "micro_metrics_4 = lunacy4.micro_validate_model(plot=False)\n",
    "micro_metrics_3 = lunacy3.micro_validate_model(plot=False)\n",
    "\n",
    "# Extract metrics\n",
    "morphologies = ['5 Lobes', '4 Lobes', '3 Lobes']\n",
    "micro_accuracies = [\n",
    "    micro_metrics_5[\"accuracy\"],\n",
    "    micro_metrics_4[\"accuracy\"],\n",
    "    micro_metrics_3[\"accuracy\"]\n",
    "]\n",
    "micro_precisions = [\n",
    "    micro_metrics_5[\"precision\"],\n",
    "    micro_metrics_4[\"precision\"],\n",
    "    micro_metrics_3[\"precision\"]\n",
    "]\n",
    "micro_recalls = [\n",
    "    micro_metrics_5[\"recall\"],\n",
    "    micro_metrics_4[\"recall\"],\n",
    "    micro_metrics_3[\"recall\"]\n",
    "]\n",
    "micro_f1_scores = [\n",
    "    micro_metrics_5[\"f1_score\"],\n",
    "    micro_metrics_4[\"f1_score\"],\n",
    "    micro_metrics_3[\"f1_score\"]\n",
    "]\n",
    "micro_specificities = [\n",
    "    micro_metrics_5[\"specificity\"],\n",
    "    micro_metrics_4[\"specificity\"],\n",
    "    micro_metrics_3[\"specificity\"]\n",
    "]\n",
    "\n",
    "\n",
    "# Updated font size\n",
    "font_size = 20\n",
    "\n",
    "# Apply font size to all relevant plot elements\n",
    "plt.rc('font', size=font_size)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=font_size)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=font_size)     # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=font_size)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=font_size)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=font_size)    # legend fontsize\n",
    "plt.rc('figure', titlesize=font_size)   # fontsize of the figure title\n",
    "\n",
    "\n",
    "# Plot micro metrics bar chart\n",
    "x = np.arange(len(morphologies))\n",
    "width = 0.15\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x - 2 * width, micro_accuracies, width, label='Accuracy')\n",
    "plt.bar(x - width, micro_precisions, width, label='Precision')\n",
    "plt.bar(x, micro_recalls, width, label='Recall')\n",
    "plt.bar(x + width, micro_f1_scores, width, label='F1 Score')\n",
    "plt.bar(x + 2 * width, micro_specificities, width, label='Specificity')\n",
    "\n",
    "plt.xlabel('Morphologies')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Micro Validation Metrics Across Morphologies')\n",
    "plt.xticks(x, morphologies)\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()\n",
    "\n",
    "# Perform macro validation for each morphology across thresholds\n",
    "thresholds = np.arange(10, 101, 10)\n",
    "macro_metrics_5 = [lunacy5.macro_validate_model(threshold, plot=False) for threshold in thresholds]\n",
    "macro_metrics_4 = [lunacy4.macro_validate_model(threshold, plot=False) for threshold in thresholds]\n",
    "macro_metrics_3 = [lunacy3.macro_validate_model(threshold, plot=False) for threshold in thresholds]\n",
    "\n",
    "# Extract macro metrics\n",
    "macro_accuracies = {\n",
    "    \"5 Lobes\": [metrics[\"accuracy\"] for metrics in macro_metrics_5],\n",
    "    \"4 Lobes\": [metrics[\"accuracy\"] for metrics in macro_metrics_4],\n",
    "    \"3 Lobes\": [metrics[\"accuracy\"] for metrics in macro_metrics_3]\n",
    "}\n",
    "macro_precisions = {\n",
    "    \"5 Lobes\": [metrics[\"precision\"] for metrics in macro_metrics_5],\n",
    "    \"4 Lobes\": [metrics[\"precision\"] for metrics in macro_metrics_4],\n",
    "    \"3 Lobes\": [metrics[\"precision\"] for metrics in macro_metrics_3]\n",
    "}\n",
    "macro_recalls = {\n",
    "    \"5 Lobes\": [metrics[\"recall\"] for metrics in macro_metrics_5],\n",
    "    \"4 Lobes\": [metrics[\"recall\"] for metrics in macro_metrics_4],\n",
    "    \"3 Lobes\": [metrics[\"recall\"] for metrics in macro_metrics_3]\n",
    "}\n",
    "macro_f1_scores = {\n",
    "    \"5 Lobes\": [metrics[\"f1_score\"] for metrics in macro_metrics_5],\n",
    "    \"4 Lobes\": [metrics[\"f1_score\"] for metrics in macro_metrics_4],\n",
    "    \"3 Lobes\": [metrics[\"f1_score\"] for metrics in macro_metrics_3]\n",
    "}\n",
    "macro_specificities = {\n",
    "    \"5 Lobes\": [metrics[\"specificity\"] for metrics in macro_metrics_5],\n",
    "    \"4 Lobes\": [metrics[\"specificity\"] for metrics in macro_metrics_4],\n",
    "    \"3 Lobes\": [metrics[\"specificity\"] for metrics in macro_metrics_3]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Color and shape code for morphologies\n",
    "colors = {'3 Lobes': 'red', '4 Lobes': 'blue', '5 Lobes': 'green'}\n",
    "markers = {'Accuracy': 'o', 'Precision': 's', 'Recall': '^', 'F1 Score': 'd', 'Specificity': 'x'}\n",
    "\n",
    "# Plot macro metrics across thresholds for each morphology\n",
    "plt.figure(figsize=(14, 8))\n",
    "for morphology, color in colors.items():\n",
    "    for metric_name, metric_dict in zip(\n",
    "        ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Specificity'],\n",
    "        [macro_accuracies, macro_precisions, macro_recalls, macro_f1_scores, macro_specificities]\n",
    "    ):\n",
    "        plt.plot(thresholds, metric_dict[morphology], label=f'{morphology} - {metric_name}',\n",
    "                 color=color, marker=markers[metric_name])\n",
    "\n",
    "plt.xlabel('Threshold (%)')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Macro Validation Metrics Across Thresholds and Morphologies')\n",
    "plt.xticks(thresholds)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc='lower left', ncol=3,fontsize=18)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a video of validation sets with loopy's preditions and locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = range(0, 1000)\n",
    "\n",
    "lunacy3.animate_samples(sample_indices, interval=500, save_as='lunacy3_validation.mp4')\n",
    "lunacy4.animate_samples(sample_indices, interval=500, save_as='lunacy4_validation.mp4')\n",
    "lunacy5.animate_samples(sample_indices, interval=500, save_as='lunacy5_validation.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lunacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
